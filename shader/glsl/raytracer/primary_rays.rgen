#version 460
#extension GL_NV_ray_tracing : require
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_nonuniform_qualifier : enable
#pragma optionNV (unroll all)
#include "../constants.h"
#include "defines.glsl"
#include "rt_helper.glsl"
#include "sky.glsl"
#include "random.glsl"
#include "globalTexture.glsl"
#include "vertexData.glsl"
#include "gbuffer.glsl"
#include "../compute/asvgf.glsl"

// Bindings
layout(binding = BINDING_OFFSET_GLOBAL_UBO, set = 0) uniform global_ubo
{
	GlobalUbo ubo;
};
layout(binding = BINDING_OFFSET_GLOBAL_UBO_PREV, set = 0) uniform global_ubo_prev
{
	GlobalUbo uboPrev;
};
#include "traceRay.glsl"
#include "lights.glsl"

bool forward;
vec3 pos_ws_x;
vec3 pos_ws_y;

#define PRIMARY_RAY_T_MAX (10000.0)
struct PrimaryRayHit{
	vec4 albedo;
	vec4 transparent;
	vec4 normal;
	uint cluster;
	vec3 pos;
	uint material;
	vec4 motion;
	float depth;
	vec4 object;
} hitData;

Ray
getRay(vec2 pos_cs)
{
	vec4 v_near = ubo.inverseViewMat * ubo.inverseProjMat * vec4(pos_cs, -1, 1.0);
	vec4 v_far  = ubo.inverseViewMat * ubo.inverseProjMat * vec4(pos_cs,  1, 1.0);
	v_near /= v_near.w;
	v_far  /= v_far.w;

	Ray ray;
	ray.origin = v_near.xyz;
	ray.direction = normalize(v_far.xyz - v_near.xyz);
	ray.t_min = 0.01;
	ray.t_max = PRIMARY_RAY_T_MAX;
	return ray;
}

Ray
getPrimaryRay(vec2 pos_cs)
{
	vec4 v_near = ubo.inverseViewMat * ubo.inverseProjMat * vec4(pos_cs, -1, 1.0);
	vec4 v_far  = ubo.inverseViewMat * ubo.inverseProjMat * vec4(pos_cs,  1, 1.0);
	v_near /= v_near.w;
	v_far  /= v_far.w;

	Ray ray;
	ray.origin = v_near.xyz;
	ray.direction = normalize(v_far.xyz - v_near.xyz);
	ray.t_min = 0.01;
	ray.t_max = PRIMARY_RAY_T_MAX;

	// add dof effect
	if(ubo.dof > 0){
		vec3 random3 = vec3(get_rng(RNG_C(120), ubo.frameIndex), get_rng(RNG_C(122), ubo.frameIndex), get_rng(RNG_C(102), ubo.frameIndex)) * 2.0 - 1.0;
		vec3 focalPoint = ray.origin + ray.direction * ubo.focalLength;
		// two variants for dof
		// 1) jitter ray origin
		// 2) jitter screen coordinates and calculate ray origin
		if(ubo.dof == 1) {
			ray.origin += random3 * ubo.aperture;
		} else {
			v_near = ubo.inverseViewMat * ubo.inverseProjMat * vec4(pos_cs + random3.xy * ubo.aperture, -1, 1.0);
			v_near /= v_near.w;
			ray.origin = v_near.xyz;
		}
		ray.direction = normalize(focalPoint.xyz - ray.origin);
	}

	if(forward)
	{
		vec3 pos_ws    = imageLoad(posFwd, ivec2(gl_LaunchIDNV.xy) / GRAD_DWN).xyz; 
		ray.origin     = ubo.camPos.xyz;
		ray.direction  = pos_ws - ray.origin;
		float len      = length(ray.direction);
		ray.direction /= len;
		ray.t_max      = len + 0.1;
	}
	return ray;
}

vec4 getTextureLod(vec2 screen_coord_cs, Triangle triangle, HitPoint hp){
	vec2 tex_coord = hp.uv0;
	Ray ray_x = getRay(screen_coord_cs + vec2(2.0 / float(gl_LaunchSizeNV.x), 0));
	Ray ray_y = getRay(screen_coord_cs - vec2(0, 2.0 / float(gl_LaunchSizeNV.y)));

	vec3 bary_x = compute_barycentric(triangle.pos, ray_x.origin, ray_x.direction);
	vec3 bary_y = compute_barycentric(triangle.pos, ray_y.origin, ray_y.direction);

	pos_ws_x= triangle.pos * bary_x;
	pos_ws_y= triangle.pos * bary_y;

	vec2 tex_coord_x = triangle.uv0 * bary_x;
	vec2 tex_coord_y = triangle.uv0 * bary_y;
	tex_coord_x -= tex_coord;
	tex_coord_y -= tex_coord;
	tex_coord_x *= 0.5;
	tex_coord_y *= 0.5;

	TextureData d = unpackTextureData(hp.tex0);
	vec4 color = vec4(0);
	vec4 tex;
	if(d.tex0 != -1){
		vec4 tex0 = global_textureGrad(d.tex0, hp.uv0, tex_coord_x, tex_coord_y);
		// if we have more tex to blend set alpha to 1
		if(d.tex1 != -1) color = vec4(tex0.xyz, 1);
		else color = tex0;

		if(d.tex0Color) color *= (hp.color0/255);
	} else return color;
	if(d.tex1 != -1){
		tex_coord = hp.uv1;
		tex_coord_x = triangle.uv1 * bary_x;
		tex_coord_y = triangle.uv1 * bary_y;
		tex_coord_x -= tex_coord;
		tex_coord_y -= tex_coord;
		tex_coord_x *= 0.5;
		tex_coord_y *= 0.5;
		vec4 tex1 = global_textureGrad(d.tex1, hp.uv1, tex_coord_x, tex_coord_y);
		if(d.tex1Color) tex1 *= (hp.color1/255);

		if(d.tex1Blend == TEX1_NORMAL_BLEND_MASK) {
			color = alpha_blend(tex1, color);
		}
		else color += tex1;
	} else return color;

	TextureData d2 = unpackTextureData(hp.tex1);
	if(d2.tex0 != -1){
		tex_coord = hp.uv2;
		tex_coord_x = triangle.uv2 * bary_x;
		tex_coord_y = triangle.uv2 * bary_y;
		tex_coord_x -= tex_coord;
		tex_coord_y -= tex_coord;
		tex_coord_x *= 0.5;
		tex_coord_y *= 0.5;
		vec4 tex2 = global_textureGrad(d2.tex0, hp.uv2, tex_coord_x, tex_coord_y);
		if(d2.tex0Color) tex2 *= (hp.color2/255);

		if(d2.tex0Blend == TEX0_NORMAL_BLEND_MASK) {
			color = alpha_blend(tex2, color);
		}
		else color += tex2;
	} else return color;
	if(d2.tex1 != -1){
		tex_coord = hp.uv3;
		tex_coord_x = triangle.uv3 * bary_x;
		tex_coord_y = triangle.uv3 * bary_y;
		tex_coord_x -= tex_coord;
		tex_coord_y -= tex_coord;
		tex_coord_x *= 0.5;
		tex_coord_y *= 0.5;
		vec4 tex3 = global_textureGrad(d2.tex1, hp.uv3, tex_coord_x, tex_coord_y);
		if(d2.tex1Color) tex3 *= (hp.color3/255);

		if(d2.tex1Blend == TEX1_NORMAL_BLEND_MASK) {
			color = alpha_blend(tex3, color);
		}
		else color += tex3;
	} 
	return color;
}

vec2 getScreenCoordinates(){
	// pixel center offset
	vec2 pixelOffset = vec2(0.5);
	// for antialiasing use jittered pixel position
	if(ubo.randomPixelOffset){
		pixelOffset = vec2(get_rng(RNG_C(100), ubo.frameIndex), get_rng(RNG_C(100), ubo.frameIndex));
	}
	const vec2 pixelCenter = vec2(gl_LaunchIDNV.xy) + pixelOffset;
	const vec2 inUV = pixelCenter/vec2(gl_LaunchSizeNV.xy);
	const vec2 screenCoordClipSpace  = inUV * 2.0 - 1.0;
	return screenCoordClipSpace;
}



void shootPrimaryRay(Ray ray, vec2 sccs){
	traceRay(ray, RAY_FIRST_PERSON_OPAQUE_VISIBLE | RAY_FIRST_PERSON_PARTICLE_VISIBLE);

	if(!found_intersection(rp) /* && !forward*/){
		hitData.albedo = sampleSky(ray.direction);
		hitData.transparent = rp.transparent;
		hitData.normal = vec4(0);
		hitData.pos = vec3(0);
		hitData.material = MATERIAL_KIND_SKY;
		hitData.depth = PRIMARY_RAY_T_MAX;

		hitData.motion = vec4(-1);
		hitData.motion.w = 9999.0;
		hitData.depth = -999;
		hitData.normal.xyz = vec3(0,0,1);
		hitData.object = vec4(-1, -1, uintBitsToFloat(uvec2(~0u)));
	} else {
		// if(!found_intersection(rp) && forward){
		// 	vec4 obj = imageLoad(objectFwd, ivec2(gl_LaunchIDNV.xy) / GRAD_DWN);
		// 	//if(obj.x != -1 && obj.y != -1 && floatBitsToUint(obj.z) != ~0u && floatBitsToUint(obj.w) != ~0u){
		// 		rp.barycentric = obj.xy;
		// 		rp.instanceID = floatBitsToUint(obj.z);
		// 		rp.primitiveID = floatBitsToUint(obj.w);
		// 	//}
		// 	//return;
		// } else {
		// 	if(forward) { /* gradient sample became occluded, mask out */
		// 		imageStore(IMG_ASVGF_GRAD_SAMPLE_POS, ivec2(gl_LaunchIDNV.xy) / GRAD_DWN, uvec4(0));
		// 	}
		// 	forward = false;
		// }


		HitPoint hp = getHitPoint(rp);
		Triangle triangle = getTriangle(rp);

		hitData.albedo = getTextureLod(sccs, triangle, hp);
		hitData.transparent = rp.transparent;
		hitData.normal.xyz = normalize(hp.normal);
		hitData.cluster = int(hp.cluster);
		hitData.material = get_material(rp);
		if(is_player(rp)) hitData.material |= MATERIAL_FLAG_PLAYER_OR_WEAPON;
		hitData.depth = rp.hit_distance;
		//if(is_light(rp)) hitData.albedo += vec4(1,0,0,0);
		hitData.object = vec4(rp.barycentric, uintBitsToFloat(rp.instanceID), uintBitsToFloat(rp.primitiveID));


		hitData.pos = hp.pos;
		//vec3 pointView = (ubo.viewMat * vec4(hitData.pos.xyz, 1.0));
		//vec3 pointViewPrev = (uboPrev.viewMat * vec4(getPrevPos(rp),1.0));
		vec4 point = ubo.projMat * ubo.viewMat * vec4(hitData.pos.xyz, 1.0);
		vec4 pointPrev = uboPrev.projMat * uboPrev.viewMat * vec4(getPrevPos(rp),1.0);
		vec3 ndc = point.xyw;
		vec3 ndcPrev = pointPrev.xyw;
		ndc.xy /= ndc.z;
		ndcPrev.xy /= ndcPrev.z;
		hitData.normal.w = ndc.z;
		//float depth = length(pointView);
		//float depthPrev = length(pointViewPrev);
		//float depth_vs_x = length(pos_ws_x - ubo.camPos.xyz);
		//float depth_vs_y = length(pos_ws_y - ubo.camPos.xyz);
		//float fwidth_depth = 1.0 / max(0.1, (abs(depth_vs_x - depth) + abs(depth_vs_y - depthPrev))); // *2 on X because we're rendering in half resolution in X dimension
		float depth_vs_x = (ubo.projMat * ubo.viewMat * vec4(pos_ws_x,    1.0)).w;
		float depth_vs_y = (ubo.projMat * ubo.viewMat * vec4(pos_ws_y,    1.0)).w;
		float fwidth_depth = 1.0 / max(1e-4, (abs(depth_vs_x - ndc.z) + abs(depth_vs_y - ndc.z)));
		hitData.depth = ndc.z;
		hitData.motion = vec4((ndcPrev.xy - ndc.xy), ndcPrev.z - ndc.z, fwidth_depth);
	}

	// uint n_encoded = encode_normal(hitData.normal.xyz);
	// vec4 depth_normal = vec4(ndc.z, uintBitsToFloat(n_encoded), 0, 0);
	// imageStore(IMG_GBUFFER_DEPTH_NORMAL, ivec2(gl_LaunchIDNV.xy), depth_normal);

}

void main() 
{
	forward = is_gradient(ivec2(gl_LaunchIDNV.xy));
	vec2 sccs = getScreenCoordinates(); // screen coordinates in clip space
	Ray ray = getPrimaryRay(sccs);
	// get distance to first opaque object
	if(!forward) {
		traceRayOpaque(ray, RAY_FIRST_PERSON_OPAQUE_VISIBLE);
		if(found_intersection(rp)) ray.t_max = rp.hit_distance + 0.5;
	}
	shootPrimaryRay(ray, sccs);

	if(forward){
		//hitData.albedo = vec4(1,0,0,1);
	}
	// store data in g buffer
	
	imageStore(objectGBuffer, ivec2(gl_LaunchIDNV.xy), hitData.object);
	imageStore(albedoGBuffer, ivec2(gl_LaunchIDNV.xy), vec4(hitData.albedo));
	imageStore(transparentGBuffer, ivec2(gl_LaunchIDNV.xy), vec4(hitData.transparent));
	imageStore(normalGBuffer, ivec2(gl_LaunchIDNV.xy), vec4(hitData.normal.xyz, hitData.depth));
	imageStore(posGBuffer, ivec2(gl_LaunchIDNV.xy), vec4(hitData.pos.xyz, hitData.cluster));
	imageStore(viewGBuffer, ivec2(gl_LaunchIDNV.xy), vec4(ray.direction.xyz, hitData.material));
	imageStore(motionGBuffer, ivec2(gl_LaunchIDNV.xy), hitData.motion);

	
}

// vkWaitForFences(qvk.device, 1, &qvk.fence_vertex_sync, VK_TRUE, ~((uint64_t)0));
// 	vkResetFences(qvk.device, 1, &qvk.fence_vertex_sync);

// 	vkpt_submit_command_buffer(cmd_buf, qvk.queue_graphics, (1 << qvk.device_count) - 1, 0, NULL, NULL, NULL, 0, NULL, NULL, qvk.fence_vertex_sync);
