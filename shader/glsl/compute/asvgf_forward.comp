#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable
#include "../constants.h"
#include "asvgf.glsl"
#include "../raytracer/gbuffer.glsl"
#include "../raytracer/rt_Helper.glsl"
#include "../raytracer/defines.glsl"
#include "../raytracer/vertexData.glsl"

layout(binding = BINDING_OFFSET_GLOBAL_UBO, set = 0) uniform global_ubo
{
	GlobalUbo ubo;
};
layout(binding = BINDING_OFFSET_GLOBAL_UBO_PREV, set = 0) uniform global_ubo_prev
{
	GlobalUbo uboPrev;
};
layout(binding = BINDING_OFFSET_RESULT_OUTPUT, set = 0, rgba8) uniform image2D image;
layout(binding = BINDING_OFFSET_INSTANCE_PREV_TO_CURR, set = 0) buffer PrevToCurr { int data[]; } prevToCurrInstance;

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

void
encrypt_tea(inout uvec2 arg)
{
	const uint key[] = {
		0xa341316c, 0xc8013ea4, 0xad90777d, 0x7e95761e
	};
	uint v0 = arg[0], v1 = arg[1];
	uint sum = 0;
	uint delta = 0x9e3779b9;

	for(int i = 0; i < 16; i++) { // XXX rounds reduced, carefully check if good
		//for(int i = 0; i < 32; i++) {
		sum += delta;
		v0 += ((v1 << 4) + key[0]) ^ (v1 + sum) ^ ((v1 >> 5) + key[1]);
		v1 += ((v0 << 4) + key[2]) ^ (v0 + sum) ^ ((v0 >> 5) + key[3]);
	}
	arg[0] = v0;
	arg[1] = v1;
}

bool projection_view_to_screen(vec3 view_pos, out vec2 screen_pos, out float distance, bool previous)
{

	vec4 clip_pos;
	if(previous)
		clip_pos = uboPrev.projMat * vec4(view_pos, 1);
	else
		clip_pos = ubo.projMat * vec4(view_pos, 1);

	vec3 normalized = clip_pos.xyz / clip_pos.w;
	screen_pos.xy = normalized.xy * 0.5 + vec2(0.5);
	distance = length(view_pos);

	return screen_pos.y > 0 && screen_pos.y < 1 && screen_pos.x > 0 && screen_pos.x < 1 && view_pos.z < 0;
	
}

void
main()
{
	ivec2 ipos = ivec2(gl_GlobalInvocationID.xy * GRAD_DWN);
	//vec2 prev_lum;
	float prev_lum;
	{
		// Find the brightest pixel in the stratum, but _not_ the same one as we used on the previous frame.
		// Picking the brightest pixel helps prevent bright trails when the light has moved.
		// If we just pick a random pixel in the the penumbra of the sun light for example,
		// there is a high chance that this pixel will not receive any sun light due to random sampling of the sun. 
		// Overall, we'll miss the changing luminance of the moving penumbra, which is very well visible.
		
		// Pull the prev. frame sample position to make sure we're not using the same pixel. 
		// It's important because keeping the same random number sequence for more than one frame
		// introduces a visible bias.

		//uint prev_grad_sample_pos = texelFetch(TEX_ASVGF_GRAD_SMPL_POS_B, ivec2(gl_GlobalInvocationID.xy), 0).x;
        uint prev_grad_sample_pos = imageLoad(gradSmplPosASVGFBufferPrev, ivec2(gl_GlobalInvocationID.xy)).x;

		ivec2 prev_strata_pos = ivec2(
			prev_grad_sample_pos >> (STRATUM_OFFSET_SHIFT * 0),
			prev_grad_sample_pos >> (STRATUM_OFFSET_SHIFT * 1)) & STRATUM_OFFSET_MASK;

		// Go over all the HF and specular color values from the previous frame to find the brightest pixel.

		ivec2 arg_max = ivec2(0);
		float lum_max = 0;
		for(int yy = 0; yy < GRAD_DWN; yy++)
			for(int xx = 0; xx < GRAD_DWN; xx++)
			{
				// Same as previous frame - skip
				if(xx == prev_strata_pos.x && yy == prev_strata_pos.y)
					continue;

				// Pull the colors
				ivec2 p = ipos + ivec2(xx, yy);
				vec3 prev_hf = imageLoad(directIlluminationGBufferPrev, p).xyz;	
				// vec3 prev_hf = unpackRGBE(texelFetch(TEX_PT_COLOR_HF, p, 0).x);
				// vec3 prev_spec = unpackRGBE(texelFetch(TEX_PT_COLOR_SPEC, p, 0).x);
				// vec2 lums = vec2(luminance(prev_hf), luminance(prev_spec));
				float lums = luminance(prev_hf);

				// // Use total luminance of diffuse ans specular as the heuristic
				// float lum_sum = lums.x + lums.y;
				float lum_sum = luminance(prev_hf);

				if(lum_sum > lum_max)
				{
					lum_max = lum_sum;
					arg_max = ivec2(xx, yy);
					prev_lum = lums;
				}
			}


		if(lum_max > 0)
		{
			// We found a suitable pixel - use it

			ipos += arg_max;
		}
		else
		{
			// We didn't find one - all pixels, maybe other than the previously used one, were black.
			// Pick a random pixel in this case.

			uvec2 arg = uvec2(gl_GlobalInvocationID.x + gl_GlobalInvocationID.y * ubo.width,
					ubo.frameIndex);
			encrypt_tea(arg);
			arg %= GRAD_DWN;

			ipos += ivec2(arg);
			// vec3 prev_hf = unpackRGBE(texelFetch(TEX_PT_COLOR_HF, ipos, 0).x);
			// vec3 prev_spec = unpackRGBE(texelFetch(TEX_PT_COLOR_SPEC, ipos, 0).x);
			// prev_lum = vec2(luminance(prev_hf), luminance(prev_spec));
			vec3 prev_hf = imageLoad(directIlluminationGBufferPrev, ipos).xyz;	
			prev_lum = luminance(prev_hf);
		}
	}

	if(any(greaterThanEqual(ipos, ivec2(ubo.width, ubo.height))))
		return;

	vec4 prevObjInfo = imageLoad(objectGBufferPrev, ipos);
	uint prevInstanceID = floatBitsToUint(prevObjInfo.z);
	uint prevPrimitiveID = floatBitsToUint(prevObjInfo.w);
	uint currInstanceID = prevToCurrInstance.data[prevInstanceID];

	if(currInstanceID == -1) return;

	RayPayload rp;
	rp.instanceID = currInstanceID;
	rp.primitiveID = prevPrimitiveID;
	rp.barycentric = prevObjInfo.xy;
	HitPoint hp = getHitPoint(rp);
	uint cluster = hp.cluster;
	uint prevCluster = getPrevCluster(rp);

	vec2 screen_pos_curr;
	float distance_curr;
	vec3 view_pos_curr = (ubo.viewMat * vec4(hp.pos, 1.0)).xyz;


	if(!projection_view_to_screen(view_pos_curr, screen_pos_curr, distance_curr, false))
	{
		return;
	}
	//if(screen_pos_curr.y > 0 && screen_pos_curr.y < 1 && screen_pos_curr.x > 0 && screen_pos_curr.x < 1) return;

	//if(prevInstanceID > 10) return;
	/* pixel coordinate of forward projected sample */
	ivec2 ipos_curr = ivec2(screen_pos_curr * vec2(ubo.width, ubo.height));

	ivec2 pos_grad    = ipos_curr / GRAD_DWN;
	ivec2 pos_stratum = ipos_curr % GRAD_DWN;

	uint gradient_idx =
		  (1 << 31) /* mark sample as busy */
		| (pos_stratum.x << (STRATUM_OFFSET_SHIFT * 0)) /* encode pos in */
		| (pos_stratum.y << (STRATUM_OFFSET_SHIFT * 1)); /* current frame */

	//imageStore(image, ivec2(ipos_curr), vec4( hp.normal.xyz,1));
	if(imageAtomicCompSwap(gradSmplPosASVGFBuffer, pos_grad, 0u, gradient_idx) != 0) {
	 	return;
	}

	vec4 tex_gradients_0 = imageLoad(texGrad0GBuffer, ipos);
	imageStore(texGradFwd0, pos_grad, tex_gradients_0);
	vec4 tex_gradients_1 = imageLoad(texGrad1GBuffer, ipos);
	imageStore(texGradFwd1, pos_grad, tex_gradients_1);
	vec4 tex_gradients_2 = imageLoad(texGrad2GBuffer, ipos);
	imageStore(texGradFwd2, pos_grad, tex_gradients_2);
	vec4 tex_gradients_3 = imageLoad(texGrad3GBuffer, ipos);
	imageStore(texGradFwd3, pos_grad, tex_gradients_3);
	imageStore(posFwd, pos_grad, vec4(hp.pos, 0.0));
	imageStore(objectFwd, pos_grad, vec4(rp.barycentric, uintBitsToFloat(rp.instanceID), uintBitsToFloat(rp.primitiveID)));
	imageStore(gradHfASVGFPing, pos_grad, vec4(prev_lum,0 , 0, 0));
}